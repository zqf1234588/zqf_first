#  Dual-Encoder Network with Contrastive Pretraining and Window Cross Attention for Robust Glaucoma Segmentation

---

## ğŸ“Œ Overview

We leverage the **Unet++** architecture, built on top of PyTorch, to segment retinal images. The project covers the full pipeline from data preprocessing, model training/testing, to result visualization and performance evaluation.

---

##  Features
-  Pretraing for REFUGE2 dataset
-  Preprocessing of REFUGE2 dataset (images + masks)
-  Unet++ model implementation for segmentation
-  Training and testing with performance logging
-  Visualization of predictions vs ground truth
-  Evaluation using standard segmentation metrics

---

## ğŸ“ Project Structure

 ```python 
.
â”œâ”€â”€ pretrain/                   # Pretrain folder
â”‚   â”œâ”€â”€ data_aug/               # Augementation method for contrastive learning
|   â”œâ”€â”€ exceptions/
â”‚   â”œâ”€â”€ datasets/           
|   |   â”œâ”€â”€ refuge2/  
|   |   |    â””â”€â”€ train/           
|   |   |        â””â”€â”€ images/    # Images for contrastive learning
|   â”œâ”€â”€ models
|   â”œâ”€â”€ run.py
|   â”œâ”€â”€ simclr.py               # Contrastive learning method
â”‚   â””â”€â”€ utils.py                # Tools for save_checkpoint, save_config_file, calculate accuracy
â”œâ”€â”€ SimCLR/                     
â”‚   â”œâ”€â”€ datasets/               # Dataset (REFUGE2)
â”‚   â”œâ”€â”€ env/                    # SMP attention method
â”‚   â”œâ”€â”€ models/                 # Duoble encoder Unet++ and apdative encoder for contrastive learning
â”‚   â”œâ”€â”€ weights/                # Path to save model
â”‚   â”œâ”€â”€ seg_train.py            # Train model run this file
â”‚   â”œâ”€â”€ Segdataloader.py        # Get different dataset
â”‚   â”œâ”€â”€ testdataset.py          # Evaluation methods
â”‚   â””â”€â”€ util.py                 # Tools for load model, getdataset and get dataloader
â”œâ”€â”€ demo.png                    # Demo picture of segmentation
â”œâ”€â”€ requirements.txt                
â””â”€â”€ README.md
```
### dataset structure
```python
â”‚   â”œâ”€â”€ refuge2/          
|   |   â”œâ”€â”€ train/  
|   |   |    â”œâ”€â”€ images/        # image
|   |   |    â””â”€â”€ mask/          # label
|   |   â”œâ”€â”€ test/  
|   |   |    â”œâ”€â”€ images/        # image
|   |   |    â””â”€â”€ mask/          # label
|   |   â”œâ”€â”€ val/  
|   |   |    â”œâ”€â”€ images/        # image
|   |   |    â””â”€â”€ mask/          # label
```
### Setup Environment
ğŸ› ï¸
python 3.9.21
pytorch 2.6.0+cu124
```python
conda create -n SimCLR python=3.9
conda activate SimCLR
pip install -r requirements.txt
```
### Pretrain
```python
python run.py -data ./datasets/refuge2/train/images -dataset-name refuge2 --log-every-n-steps 100 --epochs 500 --batch-size 4
```
### Train the Model
under the ./SimCLR directory
go to  `util.py` set your checkopoint `checkpoint = torch.load('Your pretrained weight', weights_only=True)['state_dict']` Line73,59,45
run 
```python
python seg_train.py  --doubleEncoder 1  --freeze 0 --resolution 512 --train_batch_size 4 --backbone timm-efficientnet-b5 --num_train_epochs 250
```
more dome instructions to run is in  `run.py`

### Run Inference and Visualize Results
under the ./SimCLR directory, goto `testdataset.py` adapt encoder_name to coorect backbone for model you test (line 182, 189)
under the ./SimCLR directoryrun `testdataset.py`
## Evaluation Metrics
- Dice Coefficient
- Intersection over Union (IoU)
- Precision
- Pixel-wise Accuracy
- recall
- F1
## Example Visualization
![demo.pngâ€¦]()














